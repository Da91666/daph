{
  "options": {
    "daph.home": "DAPH_HOME路径",
    "daph.log-level": "info"
  },
  "nodes": [
    {
      "flag": "Spark3.dataframe.stream.connector.CommonInput",
      "config": {
        "cfg": {
          "group.id": "kafka_consume_group_iceberg",
          "kafka.bootstrap.servers": "ddp1:9092,ddp2:9092,ddp3:9092",
          "subscribe": "dspark_mysql_user"
        },
        "format": "kafka"
      },
      "outLines": [
        "in-line1"
      ]
    },
    {
      "flag": "Spark3.dataframe.general.transformer.Sql",
      "config": {
        "sql": "select split(CAST(value AS STRING),'\\\\|')[0] as id, split(CAST(value AS STRING),'\\\\|')[1]  AS username, split( CAST(value AS STRING),'\\\\|')[2]  AS updatetime,split( CAST(value AS STRING),'\\\\|')[3]  AS createtime,split( CAST(value AS STRING),'\\\\|')[4]  AS price,split( CAST(value AS STRING),'\\\\|')[5]  AS inventory from t"
      },
      "inLines": [
        "in-line1"
      ],
      "outLines": [
        "sql-tr-line"
      ]
    },
    {
      "flag": "Spark3.dataframe.stream.connector.CommonOutput",
      "config": {
        "cfg": {
          "dbtable": "dspark_kafka_user",
          "driver": "com.mysql.cj.jdbc.Driver",
          "duplicateIncs": "",
          "password": "root",
          "url": "jdbc:mysql://192.168.3.202:3306/bigdata?characterEncoding=UTF-8&useUnicode=true&useSSL=false&tinyInt1isBit=false&allowPublicKeyRetrieval=true&serverTimezone=Asia/Shanghai",
          "user": "root"
        },
        "saveMode": "append",
        "format": "jdbc"
      },
      "inLines": [
        "sql-tr-line"
      ]
    }
  ]
}